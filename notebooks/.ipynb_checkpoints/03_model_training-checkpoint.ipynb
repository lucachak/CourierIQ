
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CourierIQ ETA Model Training\n",
    "\n",
    "This notebook walks through:\n",
    "- Data loading / generation\n",
    "- Feature exploration & visualisation\n",
    "- Model training (Random Forest + placeholders for other models)\n",
    "- Evaluation and saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Import libraries\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src to path (assumes a typical project layout)\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Custom ETA module (replace with your own implementation)\n",
    "try:\n",
    "    from src.models.eta_model import ETAPredictor, generate_synthetic_training_data\n",
    "except Exception as e:\n",
    "    print(\"Could not import custom ETA model – using placeholders instead.\")\n",
    "    # Dummy functions for the sake of the notebook\n",
    "    def generate_synthetic_training_data(n_samples=5000):\n",
    "        rng = np.random.default_rng(42)\n",
    "        timestamps = pd.date_range(\"2023-01-01\", periods=n_samples, freq=\"15min\")\n",
    "        traffic_level = rng.integers(1, 10, size=n_samples)\n",
    "        eta_seconds = rng.normal(loc=1800, scale=300, size=n_samples) + traffic_level*50\n",
    "        return pd.DataFrame({\"timestamp\": timestamps,\n",
    "                            \"traffic_level\": traffic_level,\n",
    "                            \"eta_seconds\": eta_seconds})\n",
    "\n",
    "# Set visual style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load or Generate Data\n",
    "\n",
    "If you have a real dataset you can load it here; otherwise we generate synthetic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Load real data (uncomment if available)\n",
    "# data = pd.read_csv('../src/data/processed/delivery_data.csv')\n",
    "\n",
    "# Option 2: Generate synthetic data for testing\n",
    "print(\"Generating synthetic training data...\")\n",
    "data = generate_synthetic_training_data(n_samples=5000)\n",
    "\n",
    "print(f\"Dataset shape: {data.shape}\")\n",
    "print(f\"\\nColumns: {data.columns.tolist()}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "display(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Exploration\n",
    "\n",
    "A quick look at summary statistics and missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== Data Summary ===\")\n",
    "display(data.describe())\n",
    "\n",
    "print(\"\\n=== Missing Values ===\")\n",
    "display(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualisations\n",
    "\n",
    "We’ll plot the relationship between ETA and traffic level, and look at how ETA varies by hour of day and day of week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 2x2 grid of plots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# ETA vs Traffic Level\n",
    "axes[0, 1].scatter(data['traffic_level'], data['eta_seconds'] / 60, alpha=0.3)\n",
    "axes[0, 1].set_xlabel('Traffic Level')\n",
    "axes[0, 1].set_ylabel('ETA (minutes)')\n",
    "axes[0, 1].set_title('ETA vs Traffic Level')\n",
    "\n",
    "# ETA by Hour of Day\n",
    "hourly_eta = data.groupby(data['timestamp'].dt.hour)['eta_seconds'].mean() / 60\n",
    "axes[1, 0].plot(hourly_eta.index, hourly_eta.values, marker='o')\n",
    "axes[1, 0].set_xlabel('Hour of Day')\n",
    "axes[1, 0].set_ylabel('Average ETA (minutes)')\n",
    "axes[1, 0].set_title('Average ETA by Hour')\n",
    "axes[1, 0].grid(True)\n",
    "\n",
    "# ETA by Day of Week\n",
    "daily_eta = data.groupby(data['timestamp'].dt.dayofweek)['eta_seconds'].mean() / 60\n",
    "days = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
    "axes[1, 1].bar(range(7), daily_eta.values)\n",
    "axes[1, 1].set_xticks(range(7))\n",
    "axes[1, 1].set_xticklabels(days)\n",
    "axes[1, 1].set_ylabel('Average ETA (minutes)')\n",
    "axes[1, 1].set_title('Average ETA by Day of Week')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train Models\n",
    "\n",
    "We’ll start with a Random Forest regressor and leave placeholders for other algorithms you might want to try (e.g., XGBoost, Linear Regression)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Train Random Forest\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Training Random Forest Model\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "# Features & target\n",
    "X = data[['traffic_level']]\n",
    "y = data['eta_seconds']\n",
    "\n",
    "# Train‑test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Hyperparameter grid (you can expand this as needed)\n",
    "param_grid = {\n",
    "    \"n_estimators\": [100, 200],\n",
    "    \"max_depth\": [None, 10, 20],\n",
    "    \"min_samples_split\": [2, 5]\n",
    "}\n",
    "\n",
    "# Grid search\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "grid_search = GridSearchCV(rf, param_grid, cv=3, n_jobs=-1, verbose=0)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model\n",
    "best_rf = grid_search.best_estimator_\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "\n",
    "# Evaluation on test set\n",
    "y_pred = best_rf.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"MAE: {mae:.2f} seconds\")\n",
    "print(f\"R²: {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Next steps**:\n",
    "- Add more features (timestamp, weather, etc.) and try feature engineering.\n",
    "- Try other models (XGBoost, LightGBM, linear regression, neural nets).\n",
    "- Perform cross‑validation and hyperparameter tuning on the full dataset.\n",
    "- Save the best model with `joblib` or `pickle` for later deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Optional: save model\n",
    "import joblib\n",
    "\n",
    "model_path = \"./best_random_forest_eta.pkl\"\n",
    "joblib.dump(best_rf, model_path)\n",
    "print(f\"Model saved to {model_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

